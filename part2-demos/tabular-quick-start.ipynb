{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Tabular Quick Start - Titanic Classification\n\n## 🎯 Objective\nA minimal baseline demonstrating the simplest AutoGluon workflow: **load → fit → leaderboard**\n\n**Task**: Binary Classification  \n**Dataset**: Titanic (Kaggle)  \n**Target**: `Survived`  \n**Metric**: ROC-AUC  \n\n## 📺 Video Tutorial\n\n[![AutoGluon Part 2: Tabular Demos](https://img.youtube.com/vi/WXv557L0ny4/0.jpg)](https://youtu.be/WXv557L0ny4)\n\nClick the image above to watch the complete Part 2 tutorial on YouTube!\n\n## 📋 What This Notebook Does\n1. Load Titanic dataset\n2. Train AutoGluon with ONE line of code\n3. View leaderboard and feature importance\n4. Make predictions"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📦 Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torch torchvision torchaudio\n",
    "!pip install -q autogluon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📚 Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📥 Load Dataset\n",
    "\n",
    "AutoGluon provides sample datasets including Titanic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: https://autogluon.s3.amazonaws.com/datasets/titanic/train.csv | Columns = 12 / 12 | Rows = 891 -> 891\n",
      "Loaded data from: https://autogluon.s3.amazonaws.com/datasets/titanic/test.csv | Columns = 11 / 11 | Rows = 418 -> 418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data loaded!\n",
      "   Train: (891, 12)\n",
      "   Test:  (418, 11)\n",
      "\n",
      "📊 First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Thayer)</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Thayer)  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load Titanic dataset (built-in)\n",
    "train = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/titanic/train.csv')\n",
    "test = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/titanic/test.csv')\n",
    "\n",
    "print(f\"✅ Data loaded!\")\n",
    "print(f\"   Train: {train.shape}\")\n",
    "print(f\"   Test:  {test.shape}\")\n",
    "print(f\"\\n📊 First few rows:\")\n",
    "display(train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 Set Target Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Target: Survived\n"
     ]
    }
   ],
   "source": [
    "LABEL = \"Survived\"\n",
    "print(f\"🎯 Target: {LABEL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚀 Train Model (ONE Line!)\n",
    "\n",
    "This is the simplest possible AutoGluon workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20251026_224248\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.9.6\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 25.0.0: Wed Sep 17 21:42:08 PDT 2025; root:xnu-12377.1.9~141/RELEASE_ARM64_T8132\n",
      "CPU Count:          10\n",
      "Memory Avail:       3.80 GB / 16.00 GB (23.8%)\n",
      "Disk Space Avail:   94.16 GB / 228.27 GB (41.2%)\n",
      "===================================================\n",
      "Presets specified: ['medium_quality']\n",
      "Using hyperparameters preset: hyperparameters='default'\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"/Users/banbalagan/Projects/autogluon-assignment/part2-demos/AutogluonModels/ag-20251026_224248\"\n",
      "Train Data Rows:    891\n",
      "Train Data Columns: 11\n",
      "Label Column:       Survived\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [np.int64(0), np.int64(1)]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3834.00 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.30 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['Name']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 8\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])        : 2 | ['Age', 'Fare']\n",
      "\t\t('int', [])          : 4 | ['PassengerId', 'Pclass', 'SibSp', 'Parch']\n",
      "\t\t('object', [])       : 4 | ['Sex', 'Ticket', 'Cabin', 'Embarked']\n",
      "\t\t('object', ['text']) : 1 | ['Name']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    : 3 | ['Ticket', 'Cabin', 'Embarked']\n",
      "\t\t('float', [])                       : 2 | ['Age', 'Fare']\n",
      "\t\t('int', [])                         : 4 | ['PassengerId', 'Pclass', 'SibSp', 'Parch']\n",
      "\t\t('int', ['binned', 'text_special']) : 9 | ['Name.char_count', 'Name.word_count', 'Name.capital_ratio', 'Name.lower_ratio', 'Name.special_ratio', ...]\n",
      "\t\t('int', ['bool'])                   : 1 | ['Sex']\n",
      "\t\t('int', ['text_ngram'])             : 9 | ['__nlp__.henry', '__nlp__.john', '__nlp__.master', '__nlp__.miss', '__nlp__.mr', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t11 features in original data used to generate 28 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.07 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.23s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 712, Val Rows: 179\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT ... Training model for up to 299.77s of the 299.77s of remaining time.\n",
      "\tFitting with cpus=10, gpus=0, mem=0.0/3.7 GB\n",
      "\t0.8156\t = Validation score   (accuracy)\n",
      "\t0.83s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 298.93s of the 298.93s of remaining time.\n",
      "\tFitting with cpus=10, gpus=0, mem=0.0/3.8 GB\n",
      "\t0.8212\t = Validation score   (accuracy)\n",
      "\t0.69s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ... Training model for up to 298.23s of the 298.23s of remaining time.\n",
      "\tFitting with cpus=10, gpus=0\n",
      "\t0.8156\t = Validation score   (accuracy)\n",
      "\t0.25s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ... Training model for up to 297.94s of the 297.94s of remaining time.\n",
      "\tFitting with cpus=10, gpus=0\n",
      "\t0.8156\t = Validation score   (accuracy)\n",
      "\t0.22s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 297.69s of the 297.69s of remaining time.\n",
      "\tFitting with cpus=10, gpus=0\n",
      "\t0.8268\t = Validation score   (accuracy)\n",
      "\t0.58s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ... Training model for up to 297.11s of the 297.11s of remaining time.\n",
      "\tFitting with cpus=10, gpus=0\n",
      "\t0.8101\t = Validation score   (accuracy)\n",
      "\t0.2s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ... Training model for up to 296.87s of the 296.87s of remaining time.\n",
      "\tFitting with cpus=10, gpus=0\n",
      "\t0.8045\t = Validation score   (accuracy)\n",
      "\t0.21s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 296.63s of the 296.62s of remaining time.\n",
      "\tFitting with cpus=10, gpus=0, mem=0.0/3.9 GB\n",
      "\t0.8268\t = Validation score   (accuracy)\n",
      "\t0.41s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 296.20s of the 296.20s of remaining time.\n",
      "\tFitting with cpus=10, gpus=0\n",
      "\t0.8156\t = Validation score   (accuracy)\n",
      "\t0.31s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 295.89s of the 295.88s of remaining time.\n",
      "\tFitting with cpus=10, gpus=0, mem=0.0/3.8 GB\n",
      "\t0.838\t = Validation score   (accuracy)\n",
      "\t3.19s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 292.68s of the 292.68s of remaining time.\n",
      "\tFitting with cpus=10, gpus=0, mem=0.0/3.9 GB\n",
      "\t0.8156\t = Validation score   (accuracy)\n",
      "\t2.49s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.77s of the 290.18s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetTorch': 0.667, 'NeuralNetFastAI': 0.333}\n",
      "\t0.8436\t = Validation score   (accuracy)\n",
      "\t0.06s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 9.93s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 13753.1 rows/s (179 batch size)\n",
      "Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (179 rows).\n",
      "\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/banbalagan/Projects/autogluon-assignment/part2-demos/AutogluonModels/ag-20251026_224248\")\n"
     ]
    }
   ],
   "source": [
    "# Train with default settings\n",
    "predictor = TabularPredictor(label=LABEL).fit(\n",
    "    train,\n",
    "    presets=\"medium_quality\",\n",
    "    time_limit=300  # 5 minutes for quick demo\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 Leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏆 Model Leaderboard:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestEntr</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.032627</td>\n",
       "      <td>0.026798</td>\n",
       "      <td>0.215507</td>\n",
       "      <td>0.032627</td>\n",
       "      <td>0.026798</td>\n",
       "      <td>0.215507</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestGini</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.045693</td>\n",
       "      <td>0.030488</td>\n",
       "      <td>0.249094</td>\n",
       "      <td>0.045693</td>\n",
       "      <td>0.030488</td>\n",
       "      <td>0.249094</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExtraTreesGini</td>\n",
       "      <td>0.961841</td>\n",
       "      <td>0.810056</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.049123</td>\n",
       "      <td>0.026853</td>\n",
       "      <td>0.200536</td>\n",
       "      <td>0.049123</td>\n",
       "      <td>0.026853</td>\n",
       "      <td>0.200536</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ExtraTreesEntr</td>\n",
       "      <td>0.960718</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.045828</td>\n",
       "      <td>0.025885</td>\n",
       "      <td>0.205944</td>\n",
       "      <td>0.045828</td>\n",
       "      <td>0.025885</td>\n",
       "      <td>0.205944</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>0.933782</td>\n",
       "      <td>0.837989</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>0.007868</td>\n",
       "      <td>3.190696</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>0.007868</td>\n",
       "      <td>3.190696</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.933782</td>\n",
       "      <td>0.843575</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.022956</td>\n",
       "      <td>0.013015</td>\n",
       "      <td>3.659836</td>\n",
       "      <td>0.001302</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.061544</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>0.928171</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.001850</td>\n",
       "      <td>2.493369</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.001850</td>\n",
       "      <td>2.493369</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.905724</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.003143</td>\n",
       "      <td>0.001649</td>\n",
       "      <td>0.694414</td>\n",
       "      <td>0.003143</td>\n",
       "      <td>0.001649</td>\n",
       "      <td>0.694414</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>0.892256</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.010754</td>\n",
       "      <td>0.004880</td>\n",
       "      <td>0.407596</td>\n",
       "      <td>0.010754</td>\n",
       "      <td>0.004880</td>\n",
       "      <td>0.407596</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.881033</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.006891</td>\n",
       "      <td>0.003020</td>\n",
       "      <td>0.309392</td>\n",
       "      <td>0.006891</td>\n",
       "      <td>0.003020</td>\n",
       "      <td>0.309392</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.859708</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.003607</td>\n",
       "      <td>0.001723</td>\n",
       "      <td>0.575904</td>\n",
       "      <td>0.003607</td>\n",
       "      <td>0.001723</td>\n",
       "      <td>0.575904</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>0.854097</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.002439</td>\n",
       "      <td>0.831281</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.002439</td>\n",
       "      <td>0.831281</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  score_test  score_val eval_metric  pred_time_test  \\\n",
       "0      RandomForestEntr    0.962963   0.815642    accuracy        0.032627   \n",
       "1      RandomForestGini    0.962963   0.815642    accuracy        0.045693   \n",
       "2        ExtraTreesGini    0.961841   0.810056    accuracy        0.049123   \n",
       "3        ExtraTreesEntr    0.960718   0.804469    accuracy        0.045828   \n",
       "4        NeuralNetTorch    0.933782   0.837989    accuracy        0.010900   \n",
       "5   WeightedEnsemble_L2    0.933782   0.843575    accuracy        0.022956   \n",
       "6         LightGBMLarge    0.928171   0.815642    accuracy        0.003448   \n",
       "7              LightGBM    0.905724   0.821229    accuracy        0.003143   \n",
       "8       NeuralNetFastAI    0.892256   0.826816    accuracy        0.010754   \n",
       "9               XGBoost    0.881033   0.815642    accuracy        0.006891   \n",
       "10             CatBoost    0.859708   0.826816    accuracy        0.003607   \n",
       "11           LightGBMXT    0.854097   0.815642    accuracy        0.003906   \n",
       "\n",
       "    pred_time_val  fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0        0.026798  0.215507                 0.032627                0.026798   \n",
       "1        0.030488  0.249094                 0.045693                0.030488   \n",
       "2        0.026853  0.200536                 0.049123                0.026853   \n",
       "3        0.025885  0.205944                 0.045828                0.025885   \n",
       "4        0.007868  3.190696                 0.010900                0.007868   \n",
       "5        0.013015  3.659836                 0.001302                0.000267   \n",
       "6        0.001850  2.493369                 0.003448                0.001850   \n",
       "7        0.001649  0.694414                 0.003143                0.001649   \n",
       "8        0.004880  0.407596                 0.010754                0.004880   \n",
       "9        0.003020  0.309392                 0.006891                0.003020   \n",
       "10       0.001723  0.575904                 0.003607                0.001723   \n",
       "11       0.002439  0.831281                 0.003906                0.002439   \n",
       "\n",
       "    fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0            0.215507            1       True          4  \n",
       "1            0.249094            1       True          3  \n",
       "2            0.200536            1       True          6  \n",
       "3            0.205944            1       True          7  \n",
       "4            3.190696            1       True         10  \n",
       "5            0.061544            2       True         12  \n",
       "6            2.493369            1       True         11  \n",
       "7            0.694414            1       True          2  \n",
       "8            0.407596            1       True          8  \n",
       "9            0.309392            1       True          9  \n",
       "10           0.575904            1       True          5  \n",
       "11           0.831281            1       True          1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "💾 Saved: leaderboard.csv\n"
     ]
    }
   ],
   "source": [
    "leaderboard = predictor.leaderboard(train, silent=True)\n",
    "print(\"🏆 Model Leaderboard:\")\n",
    "display(leaderboard)\n",
    "\n",
    "leaderboard.to_csv('leaderboard.csv', index=False)\n",
    "print(\"\\n💾 Saved: leaderboard.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔍 Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 11 features using 891 rows with 5 shuffle sets...\n",
      "\t2.58s\t= Expected runtime (0.52s per shuffle set)\n",
      "\t1.18s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Feature Importance:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>0.151740</td>\n",
       "      <td>0.009370</td>\n",
       "      <td>1.735942e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.171033</td>\n",
       "      <td>0.132447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticket</th>\n",
       "      <td>0.108866</td>\n",
       "      <td>0.005082</td>\n",
       "      <td>5.679910e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>0.119329</td>\n",
       "      <td>0.098403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <td>0.102581</td>\n",
       "      <td>0.010366</td>\n",
       "      <td>1.234255e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.123924</td>\n",
       "      <td>0.081238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>0.057464</td>\n",
       "      <td>0.003756</td>\n",
       "      <td>2.178048e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.065197</td>\n",
       "      <td>0.049730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>0.040404</td>\n",
       "      <td>0.006964</td>\n",
       "      <td>1.018318e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.054743</td>\n",
       "      <td>0.026065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.036588</td>\n",
       "      <td>0.006668</td>\n",
       "      <td>1.267265e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.050318</td>\n",
       "      <td>0.022858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>0.033670</td>\n",
       "      <td>0.003272</td>\n",
       "      <td>1.057024e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.040407</td>\n",
       "      <td>0.026933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cabin</th>\n",
       "      <td>0.032772</td>\n",
       "      <td>0.001844</td>\n",
       "      <td>1.198246e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.036569</td>\n",
       "      <td>0.028975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked</th>\n",
       "      <td>0.024916</td>\n",
       "      <td>0.005044</td>\n",
       "      <td>1.910308e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.035302</td>\n",
       "      <td>0.014530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <td>0.018406</td>\n",
       "      <td>0.004318</td>\n",
       "      <td>3.381574e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.027297</td>\n",
       "      <td>0.009516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0.008081</td>\n",
       "      <td>0.001844</td>\n",
       "      <td>3.040925e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.011878</td>\n",
       "      <td>0.004284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             importance    stddev       p_value  n  p99_high   p99_low\n",
       "Sex            0.151740  0.009370  1.735942e-06  5  0.171033  0.132447\n",
       "Ticket         0.108866  0.005082  5.679910e-07  5  0.119329  0.098403\n",
       "Name           0.102581  0.010366  1.234255e-05  5  0.123924  0.081238\n",
       "Pclass         0.057464  0.003756  2.178048e-06  5  0.065197  0.049730\n",
       "SibSp          0.040404  0.006964  1.018318e-04  5  0.054743  0.026065\n",
       "Age            0.036588  0.006668  1.267265e-04  5  0.050318  0.022858\n",
       "Parch          0.033670  0.003272  1.057024e-05  5  0.040407  0.026933\n",
       "Cabin          0.032772  0.001844  1.198246e-06  5  0.036569  0.028975\n",
       "Embarked       0.024916  0.005044  1.910308e-04  5  0.035302  0.014530\n",
       "PassengerId    0.018406  0.004318  3.381574e-04  5  0.027297  0.009516\n",
       "Fare           0.008081  0.001844  3.040925e-04  5  0.011878  0.004284"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "💾 Saved: feature_importance.csv\n"
     ]
    }
   ],
   "source": [
    "feature_importance = predictor.feature_importance(train)\n",
    "print(\"🔍 Feature Importance:\")\n",
    "display(feature_importance)\n",
    "\n",
    "feature_importance.to_csv('feature_importance.csv')\n",
    "print(\"\\n💾 Saved: feature_importance.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔮 Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔮 Sample predictions:\n",
      "0    0\n",
      "1    1\n",
      "2    0\n",
      "3    0\n",
      "4    1\n",
      "5    0\n",
      "6    0\n",
      "7    0\n",
      "8    1\n",
      "9    0\n",
      "Name: Survived, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "predictions = predictor.predict(test)\n",
    "print(\"🔮 Sample predictions:\")\n",
    "print(predictions.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 💾 Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved: autogluon_model.zip\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "shutil.make_archive('autogluon_model', 'zip', predictor.path)\n",
    "print(\"✅ Model saved: autogluon_model.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎓 Summary\n",
    "\n",
    "This notebook showed the **minimal AutoGluon workflow**:\n",
    "\n",
    "```python\n",
    "predictor = TabularPredictor(label=LABEL).fit(train)\n",
    "```\n",
    "\n",
    "That's it! AutoGluon handles:\n",
    "- ✅ Data preprocessing\n",
    "- ✅ Feature engineering\n",
    "- ✅ Model selection\n",
    "- ✅ Hyperparameter tuning\n",
    "- ✅ Ensemble creation\n",
    "\n",
    "**Key Findings (Typical Results):**\n",
    "- Most important features: Sex, Fare, Age, Pclass\n",
    "- Ensemble models perform best\n",
    "- ~80-85% accuracy achievable"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AutoGluon (venv)",
   "language": "python",
   "name": "autogluon-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
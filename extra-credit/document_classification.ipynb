{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoGluon: Document Classification\n",
    "\n",
    "## Objective\n",
    "This notebook demonstrates **document classification** using AutoGluon. Document classification assigns categories to documents based on their content, layout, and visual features.\n",
    "\n",
    "## Use Case\n",
    "Document classification is useful for:\n",
    "- Automated document routing in enterprises\n",
    "- Invoice vs receipt vs purchase order classification\n",
    "- Legal document categorization\n",
    "- Form type identification\n",
    "- Medical records classification\n",
    "- Email categorization\n",
    "\n",
    "## Key Features\n",
    "- Combines text content and visual layout\n",
    "- Handles scanned documents and images\n",
    "- Works with various document formats\n",
    "- Considers document structure and formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "!pip install -q torch torchvision torchaudio\n!pip install -q autogluon"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "# TODO: Upload your document dataset or use URL\n",
    "# Dataset should have:\n",
    "# - 'document' or 'image' column (paths to document images)\n",
    "# - 'label' column (document category)\n",
    "# - Optional: 'text' column (extracted text from OCR)\n",
    "\n",
    "# Example: train_data = TabularDataset('path/to/documents.csv')\n",
    "\n",
    "train_data = None  # Replace with your data\n",
    "test_data = None   # Replace with your data\n",
    "\n",
    "print(\"Dataset loaded successfully!\")\n",
    "if train_data is not None:\n",
    "    print(f\"Training data shape: {train_data.shape}\")\n",
    "    print(train_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set label column\n",
    "LABEL = 'label'  # TODO: Replace with your label column name (e.g., 'document_type', 'category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-detect problem type based on label\n",
    "if train_data is not None and LABEL in train_data.columns:\n",
    "    # Check if the label is numeric (regression) or categorical (classification)\n",
    "    if pd.api.types.is_numeric_dtype(train_data[LABEL]):\n",
    "        # Check if it's continuous or discrete\n",
    "        unique_ratio = train_data[LABEL].nunique() / len(train_data)\n",
    "        if unique_ratio > 0.05:  # More than 5% unique values suggests regression\n",
    "            problem_type = 'regression'\n",
    "            eval_metric = 'rmse'\n",
    "        else:\n",
    "            problem_type = 'classification'\n",
    "            eval_metric = 'roc_auc'\n",
    "    else:\n",
    "        problem_type = 'classification'\n",
    "        eval_metric = 'roc_auc'\n",
    "else:\n",
    "    # Default to classification for document tasks\n",
    "    problem_type = 'classification'\n",
    "    eval_metric = 'roc_auc'\n",
    "\n",
    "print(f\"Problem Type: {problem_type}\")\n",
    "print(f\"Evaluation Metric: {eval_metric}\")\n",
    "print(\"\\nNote: Document classification uses both visual and textual features.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "# AutoGluon will automatically handle document images and text\n",
    "predictor = TabularPredictor(\n",
    "    label=LABEL,\n",
    "    problem_type=problem_type,\n",
    "    eval_metric=eval_metric,\n",
    "    path='./autogluon-document-model'\n",
    ").fit(\n",
    "    train_data=train_data,\n",
    "    presets='medium_quality',\n",
    "    time_limit=900\n",
    ")\n",
    "\n",
    "print(\"Model training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display and save leaderboard\n",
    "leaderboard = predictor.leaderboard(test_data, silent=True)\n",
    "print(\"\\nModel Leaderboard:\")\n",
    "print(leaderboard)\n",
    "\n",
    "# Save leaderboard to CSV\n",
    "leaderboard.to_csv('leaderboard.csv', index=False)\n",
    "print(\"\\nLeaderboard saved to leaderboard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display and save feature importance\n",
    "try:\n",
    "    feature_importance = predictor.feature_importance(test_data)\n",
    "    print(\"\\nFeature Importance:\")\n",
    "    print(feature_importance)\n",
    "    \n",
    "    # Save feature importance to CSV\n",
    "    feature_importance.to_csv('feature_importance.csv')\n",
    "    print(\"\\nFeature importance saved to feature_importance.csv\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not compute feature importance: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "if test_data is not None:\n",
    "    predictions = predictor.predict(test_data)\n",
    "    print(\"\\nPredictions (Document Categories):\")\n",
    "    print(predictions.head())\n",
    "    \n",
    "    # For classification, also show prediction probabilities\n",
    "    if problem_type == 'classification':\n",
    "        pred_probs = predictor.predict_proba(test_data)\n",
    "        print(\"\\nPrediction Probabilities:\")\n",
    "        print(pred_probs.head())\n",
    "        \n",
    "    # Example: Classify new documents\n",
    "    print(\"\\nExample usage for new documents:\")\n",
    "    print(\"new_docs = pd.DataFrame({'document': ['path/to/invoice.jpg']})\")\n",
    "    print(\"prediction = predictor.predict(new_docs)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model artifacts as zip file\n",
    "model_path = './autogluon-document-model'\n",
    "zip_filename = 'autogluon_document_model'\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    shutil.make_archive(zip_filename, 'zip', model_path)\n",
    "    print(f\"\\nModel artifacts saved to {zip_filename}.zip\")\n",
    "else:\n",
    "    print(\"Model path not found. Train the model first.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
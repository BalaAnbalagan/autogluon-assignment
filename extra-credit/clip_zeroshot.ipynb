{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoGluon: Zero-Shot Image Classification with CLIP\n",
    "\n",
    "## Objective\n",
    "This notebook demonstrates **zero-shot image classification** using CLIP (Contrastive Language-Image Pre-training). Zero-shot learning allows classification of images into categories without training examples.\n",
    "\n",
    "## Use Case\n",
    "Zero-shot image classification is useful for:\n",
    "- Classifying images into new categories without retraining\n",
    "- Rapid prototyping for new classification tasks\n",
    "- Handling rare or emerging categories\n",
    "- Dynamic category systems\n",
    "- Custom image search with natural language queries\n",
    "\n",
    "## Key Features\n",
    "- No training data required for new categories\n",
    "- Uses natural language descriptions as class labels\n",
    "- Leverages CLIP's joint vision-language understanding\n",
    "- Can classify into arbitrary categories on-the-fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "!pip install -q torch torchvision torchaudio\n!pip install -q autogluon"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "# TODO: Upload your image dataset or use URL\n",
    "# For zero-shot classification, you need:\n",
    "# - Images (file paths in a column)\n",
    "# - Optional: labels for evaluation (not needed for inference)\n",
    "\n",
    "# Example: train_data = TabularDataset('https://your-image-dataset-url.csv')\n",
    "\n",
    "# Example placeholder - replace with your actual data\n",
    "# train_data = TabularDataset('path/to/your/image_data.csv')\n",
    "# test_data = TabularDataset('path/to/your/test_data.csv')\n",
    "\n",
    "# Note: For zero-shot, you may not need training data at all!\n",
    "# You can directly classify new images with text labels\n",
    "\n",
    "train_data = None  # Replace with your data (optional for zero-shot)\n",
    "test_data = None   # Replace with your test data\n",
    "\n",
    "print(\"Dataset loaded successfully!\")\n",
    "if train_data is not None:\n",
    "    print(f\"Training data shape: {train_data.shape}\")\n",
    "    print(train_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set label column\n",
    "LABEL = 'label'  # TODO: Replace with your label column name (if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-detect problem type based on label\n",
    "# Zero-shot classification is typically a classification task\n",
    "if train_data is not None and LABEL in train_data.columns:\n",
    "    # Check if the label is numeric (regression) or categorical (classification)\n",
    "    if pd.api.types.is_numeric_dtype(train_data[LABEL]):\n",
    "        # Check if it's continuous or discrete\n",
    "        unique_ratio = train_data[LABEL].nunique() / len(train_data)\n",
    "        if unique_ratio > 0.05:  # More than 5% unique values suggests regression\n",
    "            problem_type = 'regression'\n",
    "            eval_metric = 'rmse'\n",
    "        else:\n",
    "            problem_type = 'classification'\n",
    "            eval_metric = 'roc_auc'\n",
    "    else:\n",
    "        problem_type = 'classification'\n",
    "        eval_metric = 'roc_auc'\n",
    "else:\n",
    "    # Default to classification for zero-shot image tasks\n",
    "    problem_type = 'classification'\n",
    "    eval_metric = 'roc_auc'\n",
    "\n",
    "print(f\"Problem Type: {problem_type}\")\n",
    "print(f\"Evaluation Metric: {eval_metric}\")\n",
    "print(\"\\nNote: Zero-shot classification doesn't require training on your specific classes!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Load the model\n",
    "# For zero-shot with CLIP, we may use a pre-trained model directly\n",
    "# or fine-tune if training data is available\n",
    "\n",
    "if train_data is not None:\n",
    "    # If training data is available, fine-tune for better performance\n",
    "    predictor = TabularPredictor(\n",
    "        label=LABEL,\n",
    "        problem_type=problem_type,\n",
    "        eval_metric=eval_metric,\n",
    "        path='./autogluon-clip-model'\n",
    "    ).fit(\n",
    "        train_data=train_data,\n",
    "        presets='medium_quality',\n",
    "        time_limit=900\n",
    "    )\n",
    "    print(\"Model training completed!\")\n",
    "else:\n",
    "    # For pure zero-shot, load pre-trained CLIP model\n",
    "    print(\"No training data provided. Using pre-trained CLIP for zero-shot classification.\")\n",
    "    print(\"You can classify images by providing text descriptions of classes.\")\n",
    "    # predictor = None  # Would load pre-trained CLIP here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display and save leaderboard\n",
    "if train_data is not None and test_data is not None:\n",
    "    leaderboard = predictor.leaderboard(test_data, silent=True)\n",
    "    print(\"\\nModel Leaderboard:\")\n",
    "    print(leaderboard)\n",
    "    \n",
    "    # Save leaderboard to CSV\n",
    "    leaderboard.to_csv('leaderboard.csv', index=False)\n",
    "    print(\"\\nLeaderboard saved to leaderboard.csv\")\n",
    "else:\n",
    "    print(\"Leaderboard requires both training and test data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display and save feature importance\n",
    "try:\n",
    "    if train_data is not None:\n",
    "        feature_importance = predictor.feature_importance(test_data)\n",
    "        print(\"\\nFeature Importance:\")\n",
    "        print(feature_importance)\n",
    "        \n",
    "        # Save feature importance to CSV\n",
    "        feature_importance.to_csv('feature_importance.csv')\n",
    "        print(\"\\nFeature importance saved to feature_importance.csv\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not compute feature importance: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "if test_data is not None and train_data is not None:\n",
    "    predictions = predictor.predict(test_data)\n",
    "    print(\"\\nPredictions:\")\n",
    "    print(predictions.head())\n",
    "    \n",
    "    # For classification, also show prediction probabilities\n",
    "    if problem_type == 'classification':\n",
    "        pred_probs = predictor.predict_proba(test_data)\n",
    "        print(\"\\nPrediction Probabilities:\")\n",
    "        print(pred_probs.head())\n",
    "\n",
    "# Example: Zero-shot classification with custom text labels\n",
    "print(\"\\nZero-Shot Classification Example:\")\n",
    "print(\"You can classify images into any categories using text descriptions:\")\n",
    "print(\"\"\"\\nExample usage:\n",
    "categories = ['a photo of a cat', 'a photo of a dog', 'a photo of a bird']\n",
    "image_path = 'path/to/image.jpg'\n",
    "# Use CLIP to classify image into these categories without training!\\n\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model artifacts as zip file\n",
    "model_path = './autogluon-clip-model'\n",
    "zip_filename = 'autogluon_clip_model'\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    shutil.make_archive(zip_filename, 'zip', model_path)\n",
    "    print(f\"\\nModel artifacts saved to {zip_filename}.zip\")\n",
    "else:\n",
    "    print(\"Model path not found. Train the model first or use pre-trained CLIP.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoGluon Text: Multilingual Text Classification\n",
    "\n",
    "## Objective\n",
    "This notebook demonstrates **multilingual text classification** using AutoGluon. The model can handle text in multiple languages without requiring language-specific preprocessing.\n",
    "\n",
    "## Use Case\n",
    "Multilingual text classification is useful for:\n",
    "- Global customer support (multi-language ticket classification)\n",
    "- International social media sentiment analysis\n",
    "- Cross-language content moderation\n",
    "- Multi-market product review analysis\n",
    "- Language-agnostic document categorization\n",
    "\n",
    "## Key Features\n",
    "- Uses multilingual transformer models (e.g., mBERT, XLM-RoBERTa)\n",
    "- No need for translation or language detection\n",
    "- Handles code-switching and mixed-language text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "!pip install -q torch torchvision torchaudio\n!pip install -q autogluon"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "# TODO: Upload your multilingual text dataset or use URL\n",
    "# Your dataset should contain text in multiple languages\n",
    "# Example columns: 'text' (in various languages), 'label' (category)\n",
    "\n",
    "# Example: train_data = TabularDataset('https://your-multilingual-dataset-url.csv')\n",
    "\n",
    "# Example placeholder - replace with your actual data\n",
    "# train_data = TabularDataset('path/to/your/multilingual_data.csv')\n",
    "# test_data = TabularDataset('path/to/your/test_data.csv')\n",
    "\n",
    "train_data = None  # Replace with your data\n",
    "test_data = None   # Replace with your data\n",
    "\n",
    "print(\"Dataset loaded successfully!\")\n",
    "if train_data is not None:\n",
    "    print(f\"Training data shape: {train_data.shape}\")\n",
    "    print(\"\\nSample data (showing different languages):\")\n",
    "    print(train_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set label column\n",
    "LABEL = 'label'  # TODO: Replace with your label column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-detect problem type based on label\n",
    "if train_data is not None and LABEL in train_data.columns:\n",
    "    # Check if the label is numeric (regression) or categorical (classification)\n",
    "    if pd.api.types.is_numeric_dtype(train_data[LABEL]):\n",
    "        # Check if it's continuous or discrete\n",
    "        unique_ratio = train_data[LABEL].nunique() / len(train_data)\n",
    "        if unique_ratio > 0.05:  # More than 5% unique values suggests regression\n",
    "            problem_type = 'regression'\n",
    "            eval_metric = 'rmse'\n",
    "        else:\n",
    "            problem_type = 'classification'\n",
    "            eval_metric = 'roc_auc'\n",
    "    else:\n",
    "        problem_type = 'classification'\n",
    "        eval_metric = 'roc_auc'\n",
    "else:\n",
    "    # Default to classification for multilingual text tasks\n",
    "    problem_type = 'classification'\n",
    "    eval_metric = 'roc_auc'\n",
    "\n",
    "print(f\"Problem Type: {problem_type}\")\n",
    "print(f\"Evaluation Metric: {eval_metric}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with multilingual support\n",
    "# AutoGluon will automatically use multilingual models when text is detected\n",
    "predictor = TabularPredictor(\n",
    "    label=LABEL,\n",
    "    problem_type=problem_type,\n",
    "    eval_metric=eval_metric,\n",
    "    path='./autogluon-multilingual-model'\n",
    ").fit(\n",
    "    train_data=train_data,\n",
    "    presets='medium_quality',\n",
    "    time_limit=900,\n",
    "    # AutoGluon will automatically select multilingual models\n",
    "    # like xlm-roberta-base for multilingual text\n",
    ")\n",
    "\n",
    "print(\"Model training completed!\")\n",
    "print(\"The model can now handle text in multiple languages.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display and save leaderboard\n",
    "leaderboard = predictor.leaderboard(test_data, silent=True)\n",
    "print(\"\\nModel Leaderboard:\")\n",
    "print(leaderboard)\n",
    "\n",
    "# Save leaderboard to CSV\n",
    "leaderboard.to_csv('leaderboard.csv', index=False)\n",
    "print(\"\\nLeaderboard saved to leaderboard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display and save feature importance\n",
    "try:\n",
    "    feature_importance = predictor.feature_importance(test_data)\n",
    "    print(\"\\nFeature Importance:\")\n",
    "    print(feature_importance)\n",
    "    \n",
    "    # Save feature importance to CSV\n",
    "    feature_importance.to_csv('feature_importance.csv')\n",
    "    print(\"\\nFeature importance saved to feature_importance.csv\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not compute feature importance: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "if test_data is not None:\n",
    "    predictions = predictor.predict(test_data)\n",
    "    print(\"\\nPredictions:\")\n",
    "    print(predictions.head())\n",
    "    \n",
    "    # For classification, also show prediction probabilities\n",
    "    if problem_type == 'classification':\n",
    "        pred_probs = predictor.predict_proba(test_data)\n",
    "        print(\"\\nPrediction Probabilities:\")\n",
    "        print(pred_probs.head())\n",
    "        \n",
    "    # Example: Predict on multilingual text\n",
    "    print(\"\\nExample predictions on different languages:\")\n",
    "    print(\"(Replace with your own multilingual text for testing)\")\n",
    "    # multilingual_examples = pd.DataFrame({\n",
    "    #     'text': [\n",
    "    #         'This product is amazing!',  # English\n",
    "    #         'Ce produit est incroyable!',  # French\n",
    "    #         'この製品は素晴らしい！',  # Japanese\n",
    "    #         '¡Este producto es increíble!'  # Spanish\n",
    "    #     ]\n",
    "    # })\n",
    "    # print(predictor.predict(multilingual_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model artifacts as zip file\n",
    "model_path = './autogluon-multilingual-model'\n",
    "zip_filename = 'autogluon_multilingual_model'\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    shutil.make_archive(zip_filename, 'zip', model_path)\n",
    "    print(f\"\\nModel artifacts saved to {zip_filename}.zip\")\n",
    "else:\n",
    "    print(\"Model path not found. Train the model first.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoGluon: Time Series Forecasting with Chronos\n",
    "\n",
    "## Objective\n",
    "This notebook demonstrates **time series forecasting** using AutoGluon with Chronos, a foundation model for time series. Chronos leverages pre-trained models for improved forecasting.\n",
    "\n",
    "## Use Case\n",
    "Chronos-based forecasting is useful for:\n",
    "- Zero-shot forecasting on new time series\n",
    "- Limited historical data scenarios\n",
    "- Multiple diverse time series patterns\n",
    "- Transfer learning for time series\n",
    "- Rapid prototyping without extensive tuning\n",
    "\n",
    "## Key Features\n",
    "- Pre-trained on large-scale time series data\n",
    "- Works well with limited data\n",
    "- Generalizes across different domains\n",
    "- Handles various time series patterns\n",
    "- Reduced training time compared to from-scratch models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install AutoGluon\n",
    "!pip install -q autogluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "# TODO: Upload your time series dataset or use URL\n",
    "# Time series data should have:\n",
    "# - Timestamp column (date/datetime)\n",
    "# - Target value column (what you want to forecast)\n",
    "# - Optional: Item/entity ID for multiple time series\n",
    "\n",
    "# Chronos works particularly well with:\n",
    "# - Short time series (limited historical data)\n",
    "# - Multiple heterogeneous time series\n",
    "# - Time series from new domains\n",
    "\n",
    "# Example: train_data = TabularDataset('path/to/timeseries_data.csv')\n",
    "\n",
    "train_data = None  # Replace with your data\n",
    "test_data = None   # Replace with your data\n",
    "\n",
    "print(\"Dataset loaded successfully!\")\n",
    "if train_data is not None:\n",
    "    print(f\"Training data shape: {train_data.shape}\")\n",
    "    print(\"\\nColumn types:\")\n",
    "    print(train_data.dtypes)\n",
    "    print(\"\\nSample data:\")\n",
    "    print(train_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set label column (target variable to forecast)\n",
    "LABEL = 'target'  # TODO: Replace with your target column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-detect problem type based on label\n",
    "# Time series forecasting is typically a regression problem\n",
    "if train_data is not None and LABEL in train_data.columns:\n",
    "    # Check if the label is numeric (regression) or categorical (classification)\n",
    "    if pd.api.types.is_numeric_dtype(train_data[LABEL]):\n",
    "        # Check if it's continuous or discrete\n",
    "        unique_ratio = train_data[LABEL].nunique() / len(train_data)\n",
    "        if unique_ratio > 0.05:  # More than 5% unique values suggests regression\n",
    "            problem_type = 'regression'\n",
    "            eval_metric = 'rmse'\n",
    "        else:\n",
    "            problem_type = 'classification'\n",
    "            eval_metric = 'roc_auc'\n",
    "    else:\n",
    "        problem_type = 'classification'\n",
    "        eval_metric = 'roc_auc'\n",
    "else:\n",
    "    # Default to regression for time series\n",
    "    problem_type = 'regression'\n",
    "    eval_metric = 'rmse'\n",
    "\n",
    "print(f\"Problem Type: {problem_type}\")\n",
    "print(f\"Evaluation Metric: {eval_metric}\")\n",
    "print(\"\\nNote: Using Chronos foundation model for time series forecasting.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with Chronos\n",
    "# Chronos is a pre-trained foundation model for time series\n",
    "# It can be used directly or fine-tuned on your data\n",
    "\n",
    "predictor = TabularPredictor(\n",
    "    label=LABEL,\n",
    "    problem_type=problem_type,\n",
    "    eval_metric=eval_metric,\n",
    "    path='./autogluon-chronos-model'\n",
    ").fit(\n",
    "    train_data=train_data,\n",
    "    presets='medium_quality',\n",
    "    time_limit=900,\n",
    "    # For Chronos-based forecasting:\n",
    "    # - Can use pre-trained Chronos models\n",
    "    # - Optional fine-tuning on your data\n",
    "    # - Works well even with limited training data\n",
    ")\n",
    "\n",
    "print(\"Model training completed!\")\n",
    "print(\"Chronos-based model leverages pre-trained time series knowledge.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display and save leaderboard\n",
    "leaderboard = predictor.leaderboard(test_data, silent=True)\n",
    "print(\"\\nModel Leaderboard:\")\n",
    "print(leaderboard)\n",
    "\n",
    "# Save leaderboard to CSV\n",
    "leaderboard.to_csv('leaderboard.csv', index=False)\n",
    "print(\"\\nLeaderboard saved to leaderboard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display and save feature importance\n",
    "try:\n",
    "    feature_importance = predictor.feature_importance(test_data)\n",
    "    print(\"\\nFeature Importance:\")\n",
    "    print(feature_importance)\n",
    "    \n",
    "    # Save feature importance to CSV\n",
    "    feature_importance.to_csv('feature_importance.csv')\n",
    "    print(\"\\nFeature importance saved to feature_importance.csv\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not compute feature importance: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "if test_data is not None:\n",
    "    predictions = predictor.predict(test_data)\n",
    "    print(\"\\nPredictions (Forecasted Values):\")\n",
    "    print(predictions.head())\n",
    "    \n",
    "    # Compare with actual values if available\n",
    "    if LABEL in test_data.columns:\n",
    "        results = pd.DataFrame({\n",
    "            'Actual': test_data[LABEL],\n",
    "            'Predicted': predictions\n",
    "        })\n",
    "        print(\"\\nActual vs Predicted:\")\n",
    "        print(results.head(10))\n",
    "        \n",
    "    # Chronos advantages\n",
    "    print(\"\\nChronos Model Advantages:\")\n",
    "    print(\"- Pre-trained on diverse time series data\")\n",
    "    print(\"- Works well with limited historical data\")\n",
    "    print(\"- Generalizes across different domains\")\n",
    "    print(\"- Reduced training time\")\n",
    "    print(\"- Good zero-shot performance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model artifacts as zip file\n",
    "model_path = './autogluon-chronos-model'\n",
    "zip_filename = 'autogluon_chronos_model'\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    shutil.make_archive(zip_filename, 'zip', model_path)\n",
    "    print(f\"\\nModel artifacts saved to {zip_filename}.zip\")\n",
    "else:\n",
    "    print(\"Model path not found. Train the model first.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

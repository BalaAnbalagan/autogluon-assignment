{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoGluon Tabular: GPU-Accelerated Training\n",
    "\n",
    "## Objective\n",
    "This notebook demonstrates **GPU-accelerated training** for tabular data using AutoGluon. GPUs can significantly speed up training for large datasets and deep learning models.\n",
    "\n",
    "## Use Case\n",
    "GPU acceleration is beneficial for:\n",
    "- Large-scale tabular datasets (millions of rows)\n",
    "- Deep neural network models\n",
    "- Faster experimentation and iteration\n",
    "- Production environments requiring quick model updates\n",
    "\n",
    "## Requirements\n",
    "- CUDA-compatible GPU\n",
    "- CUDA toolkit installed\n",
    "- GPU-enabled version of relevant libraries (PyTorch, XGBoost, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install AutoGluon\n",
    "!pip install -q autogluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "import os\n",
    "import shutil\n",
    "import torch\n",
    "\n",
    "# Check GPU availability\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "# TODO: Upload your dataset or use URL\n",
    "# Example: train_data = TabularDataset('https://your-dataset-url.csv')\n",
    "\n",
    "# Example placeholder - replace with your actual data\n",
    "# train_data = TabularDataset('path/to/your/data.csv')\n",
    "# test_data = TabularDataset('path/to/your/test_data.csv')\n",
    "\n",
    "train_data = None  # Replace with your data\n",
    "test_data = None   # Replace with your data\n",
    "\n",
    "print(\"Dataset loaded successfully!\")\n",
    "if train_data is not None:\n",
    "    print(f\"Training data shape: {train_data.shape}\")\n",
    "    print(train_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set label column\n",
    "LABEL = 'target'  # TODO: Replace with your label column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-detect problem type based on label\n",
    "if train_data is not None and LABEL in train_data.columns:\n",
    "    # Check if the label is numeric (regression) or categorical (classification)\n",
    "    if pd.api.types.is_numeric_dtype(train_data[LABEL]):\n",
    "        # Check if it's continuous or discrete\n",
    "        unique_ratio = train_data[LABEL].nunique() / len(train_data)\n",
    "        if unique_ratio > 0.05:  # More than 5% unique values suggests regression\n",
    "            problem_type = 'regression'\n",
    "            eval_metric = 'rmse'\n",
    "        else:\n",
    "            problem_type = 'classification'\n",
    "            eval_metric = 'roc_auc'\n",
    "    else:\n",
    "        problem_type = 'classification'\n",
    "        eval_metric = 'roc_auc'\n",
    "else:\n",
    "    # Default to classification\n",
    "    problem_type = 'classification'\n",
    "    eval_metric = 'roc_auc'\n",
    "\n",
    "print(f\"Problem Type: {problem_type}\")\n",
    "print(f\"Evaluation Metric: {eval_metric}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with GPU acceleration\n",
    "# AutoGluon will automatically use GPU if available\n",
    "predictor = TabularPredictor(\n",
    "    label=LABEL,\n",
    "    problem_type=problem_type,\n",
    "    eval_metric=eval_metric,\n",
    "    path='./autogluon-gpu-model'\n",
    ").fit(\n",
    "    train_data=train_data,\n",
    "    presets='medium_quality',\n",
    "    time_limit=900,\n",
    "    # GPU-specific settings\n",
    "    num_gpus=1,  # Use 1 GPU (adjust based on your system)\n",
    "    # ag_args_fit={'num_gpus': 1}  # Alternative way to specify GPU usage\n",
    ")\n",
    "\n",
    "print(\"Model training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display and save leaderboard\n",
    "leaderboard = predictor.leaderboard(test_data, silent=True)\n",
    "print(\"\\nModel Leaderboard:\")\n",
    "print(leaderboard)\n",
    "\n",
    "# Save leaderboard to CSV\n",
    "leaderboard.to_csv('leaderboard.csv', index=False)\n",
    "print(\"\\nLeaderboard saved to leaderboard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display and save feature importance\n",
    "try:\n",
    "    feature_importance = predictor.feature_importance(test_data)\n",
    "    print(\"\\nFeature Importance:\")\n",
    "    print(feature_importance)\n",
    "    \n",
    "    # Save feature importance to CSV\n",
    "    feature_importance.to_csv('feature_importance.csv')\n",
    "    print(\"\\nFeature importance saved to feature_importance.csv\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not compute feature importance: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "if test_data is not None:\n",
    "    predictions = predictor.predict(test_data)\n",
    "    print(\"\\nPredictions:\")\n",
    "    print(predictions.head())\n",
    "    \n",
    "    # For classification, also show prediction probabilities\n",
    "    if problem_type == 'classification':\n",
    "        pred_probs = predictor.predict_proba(test_data)\n",
    "        print(\"\\nPrediction Probabilities:\")\n",
    "        print(pred_probs.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model artifacts as zip file\n",
    "model_path = './autogluon-gpu-model'\n",
    "zip_filename = 'autogluon_gpu_model'\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    shutil.make_archive(zip_filename, 'zip', model_path)\n",
    "    print(f\"\\nModel artifacts saved to {zip_filename}.zip\")\n",
    "else:\n",
    "    print(\"Model path not found. Train the model first.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IEEE-CIS Fraud Detection (Binary Classification)\n",
    "\n",
    "## ğŸ¯ Objective\n",
    "Build an AutoML binary classifier to detect fraudulent transactions using AutoGluon.\n",
    "\n",
    "**Task**: Binary Classification  \n",
    "**Dataset**: IEEE-CIS Fraud Detection (Kaggle)  \n",
    "**Target**: `isFraud`  \n",
    "**Metric**: ROC-AUC  \n",
    "\n",
    "## ğŸ“‹ What This Notebook Does\n",
    "1. Install AutoGluon and dependencies\n",
    "2. Load transaction and identity data from Kaggle\n",
    "3. Merge datasets and prepare features\n",
    "4. Train AutoGluon predictor with automatic model selection\n",
    "5. Show leaderboard and feature importance\n",
    "6. Generate predictions and save artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¦ Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "!pip install -q torch torchvision torchaudio\n!pip install -q autogluon kaggle"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“š Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import zipfile\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¥ Load Dataset\n",
    "\n",
    "### Option A: Kaggle API (Recommended)\n",
    "1. Go to https://www.kaggle.com/settings/account\n",
    "2. Click \"Create New API Token\" to download `kaggle.json`\n",
    "3. Upload it when prompted below\n",
    "\n",
    "### Option B: Manual Upload\n",
    "1. Download these 4 CSVs from [Kaggle Competition](https://www.kaggle.com/c/ieee-fraud-detection/data)\n",
    "   - train_transaction.csv\n",
    "   - train_identity.csv\n",
    "   - test_transaction.csv\n",
    "   - test_identity.csv\n",
    "2. Upload them when prompted below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose data loading method\n",
    "USE_KAGGLE_API = False  # Set to True to use Kaggle API, False for manual upload\n",
    "COMPETITION = \"ieee-fraud-detection\"\n",
    "\n",
    "if USE_KAGGLE_API:\n",
    "    # Upload kaggle.json\n",
    "    from google.colab import files\n",
    "    print(\"ğŸ“¤ Upload your kaggle.json file:\")\n",
    "    uploaded = files.upload()\n",
    "    \n",
    "    # Set up Kaggle credentials\n",
    "    os.makedirs('/root/.kaggle', exist_ok=True)\n",
    "    !mv kaggle.json /root/.kaggle/kaggle.json\n",
    "    !chmod 600 /root/.kaggle/kaggle.json\n",
    "    \n",
    "    # Download competition data\n",
    "    os.makedirs('data', exist_ok=True)\n",
    "    print(f\"\\nğŸ“¥ Downloading {COMPETITION} dataset...\")\n",
    "    !kaggle competitions download -c $COMPETITION -p data\n",
    "    \n",
    "    # Unzip all archives\n",
    "    print(\"\\nğŸ“‚ Extracting files...\")\n",
    "    for filename in os.listdir('data'):\n",
    "        if filename.endswith('.zip'):\n",
    "            with zipfile.ZipFile(os.path.join('data', filename), 'r') as zip_ref:\n",
    "                zip_ref.extractall('data')\n",
    "    print(\"âœ… Data downloaded and extracted!\")\n",
    "    \n",
    "else:\n",
    "    # Manual upload\n",
    "    from google.colab import files\n",
    "    print(\"ğŸ“¤ Upload these 4 files:\")\n",
    "    print(\"   1. train_transaction.csv\")\n",
    "    print(\"   2. train_identity.csv\")\n",
    "    print(\"   3. test_transaction.csv\")\n",
    "    print(\"   4. test_identity.csv\")\n",
    "    uploaded = files.upload()\n",
    "    \n",
    "    # Move files to data directory\n",
    "    os.makedirs('data', exist_ok=True)\n",
    "    for filename in uploaded.keys():\n",
    "        shutil.move(filename, os.path.join('data', filename))\n",
    "    print(\"âœ… Files uploaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”§ Load and Merge Data\n",
    "\n",
    "The dataset has two parts:\n",
    "- **Transaction data**: Payment details, amounts, cards\n",
    "- **Identity data**: Device and network information\n",
    "\n",
    "We'll merge them on `TransactionID`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load transaction data\n",
    "print(\"ğŸ“– Loading transaction data...\")\n",
    "train_transaction = pd.read_csv('data/train_transaction.csv')\n",
    "train_identity = pd.read_csv('data/train_identity.csv')\n",
    "test_transaction = pd.read_csv('data/test_transaction.csv')\n",
    "test_identity = pd.read_csv('data/test_identity.csv')\n",
    "\n",
    "# Merge transaction and identity data\n",
    "print(\"ğŸ”— Merging datasets...\")\n",
    "train = train_transaction.merge(train_identity, on='TransactionID', how='left')\n",
    "test = test_transaction.merge(test_identity, on='TransactionID', how='left')\n",
    "\n",
    "print(f\"\\nâœ… Data loaded successfully!\")\n",
    "print(f\"   Train shape: {train.shape}\")\n",
    "print(f\"   Test shape: {test.shape}\")\n",
    "print(f\"\\nğŸ“Š Target distribution:\")\n",
    "print(train['isFraud'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ Set Target Label and Problem Type\n",
    "\n",
    "AutoGluon will automatically detect this is a binary classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target label\n",
    "LABEL = \"isFraud\"\n",
    "\n",
    "# AutoGluon will auto-detect problem type (binary classification)\n",
    "# and use ROC-AUC as the metric\n",
    "print(f\"ğŸ¯ Target Label: {LABEL}\")\n",
    "print(f\"ğŸ“ˆ Metric: ROC-AUC (auto-detected for binary classification)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸš€ Train AutoGluon Model\n",
    "\n",
    "AutoGluon will:\n",
    "- Automatically handle missing values\n",
    "- Engineer features\n",
    "- Train multiple models (LightGBM, CatBoost, Neural Networks, etc.)\n",
    "- Create an ensemble of the best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create save directory with timestamp\n",
    "save_dir = f\"ag-{int(time.time())}-ieee-fraud\"\n",
    "\n",
    "# Initialize predictor\n",
    "predictor = TabularPredictor(\n",
    "    label=LABEL,\n",
    "    problem_type=\"binary\",  # Explicitly set for clarity\n",
    "    eval_metric=\"roc_auc\",  # ROC-AUC for binary classification\n",
    "    path=save_dir\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "print(\"ğŸ‹ï¸ Training AutoGluon models...\")\n",
    "print(\"This may take 15-20 minutes...\\n\")\n",
    "\n",
    "predictor = predictor.fit(\n",
    "    train,\n",
    "    presets=\"medium_quality\",  # Balance between speed and accuracy\n",
    "    time_limit=900,            # 15 minutes (adjust as needed)\n",
    "    verbosity=2                # Show detailed progress\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Model Leaderboard\n",
    "\n",
    "Shows all models trained and their performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get leaderboard\n",
    "leaderboard = predictor.leaderboard(train, silent=True)\n",
    "\n",
    "print(\"ğŸ† Top 10 Models:\")\n",
    "display(leaderboard.head(10))\n",
    "\n",
    "# Save leaderboard\n",
    "leaderboard.to_csv('leaderboard.csv', index=False)\n",
    "print(\"\\nğŸ’¾ Saved: leaderboard.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ” Feature Importance\n",
    "\n",
    "Shows which features are most predictive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance\n",
    "feature_importance = predictor.feature_importance(train)\n",
    "\n",
    "print(\"ğŸ” Top 20 Most Important Features:\")\n",
    "display(feature_importance.head(20))\n",
    "\n",
    "# Save feature importance\n",
    "feature_importance.to_csv('feature_importance.csv')\n",
    "print(\"\\nğŸ’¾ Saved: feature_importance.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”® Generate Predictions\n",
    "\n",
    "Create submission file for Kaggle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities for the positive class (fraud)\n",
    "print(\"ğŸ”® Generating predictions...\")\n",
    "predictions = predictor.predict_proba(test)\n",
    "\n",
    "# For binary classification, get probability of class 1 (fraud)\n",
    "if isinstance(predictions, pd.DataFrame):\n",
    "    fraud_proba = predictions[1]  # Probability of fraud\n",
    "else:\n",
    "    fraud_proba = predictions\n",
    "\n",
    "# Create submission file\n",
    "submission = pd.DataFrame({\n",
    "    'TransactionID': test['TransactionID'],\n",
    "    'isFraud': fraud_proba\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"âœ… Predictions generated!\")\n",
    "print(\"\\nğŸ“Š Sample predictions:\")\n",
    "display(submission.head(10))\n",
    "print(\"\\nğŸ’¾ Saved: submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ’¾ Save Model Artifacts\n",
    "\n",
    "Package everything for download:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model archive\n",
    "print(\"ğŸ“¦ Creating model archive...\")\n",
    "shutil.make_archive('autogluon_model', 'zip', save_dir)\n",
    "\n",
    "print(\"\\nâœ… All artifacts saved!\")\n",
    "print(\"\\nğŸ“¥ Download these files:\")\n",
    "print(\"   âœ“ autogluon_model.zip    - Trained model\")\n",
    "print(\"   âœ“ leaderboard.csv         - Model comparison\")\n",
    "print(\"   âœ“ feature_importance.csv  - Important features\")\n",
    "print(\"   âœ“ submission.csv          - Kaggle submission\")\n",
    "print(\"\\nğŸ’¡ Use the Files panel (ğŸ“) to download\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "1. âœ… Loading Kaggle competition data\n",
    "2. âœ… Merging transaction and identity datasets\n",
    "3. âœ… Training AutoGluon with automatic model selection\n",
    "4. âœ… Evaluating model performance via leaderboard\n",
    "5. âœ… Analyzing feature importance\n",
    "6. âœ… Generating Kaggle submission file\n",
    "\n",
    "**Next Steps:**\n",
    "- Submit `submission.csv` to Kaggle competition\n",
    "- Try different presets (`best_quality`, `high_quality`)\n",
    "- Increase `time_limit` for better results\n",
    "- Experiment with feature engineering"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}